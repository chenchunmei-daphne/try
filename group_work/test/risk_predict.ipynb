{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cd46629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from torch.optim.lr_scheduler import StepLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a278530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 检查GPU可用性\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733008f2",
   "metadata": {},
   "source": [
    "## 数据划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1324fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"insurance_data_preprocessed.csv\")\n",
    "# 只保留风险评分作为目标变量\n",
    "X = data.drop(['avg_claim_amount', 'total_claims_paid', 'annual_medical_cost', 'claims_count', 'risk_score', 'is_high_risk'], axis=1, errors='ignore')\n",
    "y = data['risk_score']  # 只预测风险评分\n",
    "\n",
    "# 检查原始risk_score的范围\n",
    "print(f\"Original risk_score range: [{y.min():.3f}, {y.max():.3f}]\")\n",
    "\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# X_val, X_test, y_val, y_test = train_test_split(\n",
    "#     X_test0, y_test, test_size=0.5,  \n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "print(f\"Dataset Size:\")\n",
    "print(f\"Training set: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "# print(f\"Validation set: {len(X_val)} samples ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")    \n",
    "\n",
    "# 转换为PyTorch张量（先创建CPU张量）\n",
    "X_train_tensor = torch.FloatTensor(X_train.values)\n",
    "# X_val_tensor = torch.FloatTensor(X_val.values)\n",
    "X_test_tensor = torch.FloatTensor(X_test.values)\n",
    "\n",
    "y_train_tensor = torch.FloatTensor(y_train.values)\n",
    "# y_val_tensor = torch.FloatTensor(y_val.values)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values)\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "batch_size = 64  # 使用更合理的批次大小\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0fb70a",
   "metadata": {},
   "source": [
    "## 定义前馈网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b81d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskScoreNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers=[256, 128, 64], dropout_rate=0.2):\n",
    "        super(RiskScoreNet, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        # 构建隐藏层\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        self.hidden_layers = nn.Sequential(*layers)\n",
    "        \n",
    "        # 输出层\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(prev_size, 1),\n",
    "            nn.Sigmoid()  # 确保输出在0~1之间\n",
    "        )\n",
    "        \n",
    "        # 权重初始化\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.hidden_layers(x)\n",
    "        risk_score = self.output_layer(features)\n",
    "        return risk_score\n",
    "\n",
    "# 初始化模型并移动到GPU\n",
    "input_size = X_train_tensor.shape[1]\n",
    "model = RiskScoreNet(input_size=input_size).to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "lr = 0.005\n",
    "step_size, gamma = 100, 0.5\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "scheduler = StepLR(optimizer, step_size, gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc36b2c2",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cdaee48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "Epoch [10/500]\n",
      "  Train Loss: 0.031080\n",
      "Epoch [20/500]\n",
      "  Train Loss: 0.030529\n",
      "Epoch [30/500]\n",
      "  Train Loss: 0.030099\n",
      "Epoch [40/500]\n",
      "  Train Loss: 0.031968\n",
      "Epoch [50/500]\n",
      "  Train Loss: 0.031673\n",
      "Epoch [60/500]\n",
      "  Train Loss: 0.031973\n",
      "Epoch [70/500]\n",
      "  Train Loss: 0.031811\n",
      "Epoch [80/500]\n",
      "  Train Loss: 0.031784\n",
      "Epoch [90/500]\n",
      "  Train Loss: 0.032333\n",
      "Epoch [100/500]\n",
      "  Train Loss: 0.033125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 反向传播\u001b[39;00m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 梯度裁剪\u001b[39;00m\n\u001b[1;32m     30\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/da_venv/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/da_venv/lib/python3.10/site-packages/torch/autograd/__init__.py:345\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    336\u001b[0m     tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(tensors)\n\u001b[1;32m    337\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    338\u001b[0m     (inputs,)\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch\u001b[38;5;241m.\u001b[39mTensor, graph\u001b[38;5;241m.\u001b[39mGradientEdge))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    343\u001b[0m )\n\u001b[0;32m--> 345\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_or_tensors_to_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _make_grads(tensors, grad_tensors_, is_grads_batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练参数\n",
    "num_epochs = 500\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "learning_rates = []\n",
    "\n",
    "print(\"Start Training...\")\n",
    "time_start = time.time()    \n",
    "for epoch in range(num_epochs):\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # 将批次数据移动到GPU\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device).view(-1, 1)  # 确保形状正确\n",
    "        \n",
    "        # 前向传播\n",
    "        pred_score = model(batch_X)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(pred_score, batch_y)\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # 梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_train_loss += loss.item()\n",
    "    \n",
    "    # # 将验证集数据移动到GPU\n",
    "    # X_val_gpu = X_val_tensor.to(device)\n",
    "    # y_val_gpu = y_val_tensor.to(device).view(-1, 1)\n",
    "    \n",
    "    # # 验证阶段\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     val_pred_score = model(X_val_gpu)\n",
    "    #     val_loss = criterion(val_pred_score, y_val_gpu)\n",
    "    \n",
    "    # # 学习率调度\n",
    "    # scheduler.step(val_loss)\n",
    "    # current_lr = optimizer.param_groups[0]['lr']\n",
    "    # learning_rates.append(current_lr)\n",
    "    \n",
    "    # # 记录损失\n",
    "    train_losses.append(epoch_train_loss / len(train_loader))\n",
    "    # val_losses.append(val_loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0 :\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'  Train Loss: {train_losses[-1]:.6f}')\n",
    "        # print(f'  Learning Rate: {current_lr:.6f}')\n",
    "        \n",
    "        # # 检查风险评分的统计信息\n",
    "        # with torch.no_grad():\n",
    "        #     print(f'  Risk Score - Min: {val_pred_score.min().item():.4f}, Max: {val_pred_score.max().item():.4f}, Mean: {val_pred_score.mean().item():.4f}')\n",
    "        # print('-' * 50)\n",
    "time_end = time.time()\n",
    "print(f'Training Time: {time_end - time_start:.2f}s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724512a1",
   "metadata": {},
   "source": [
    "### 验证模型效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将测试集数据移动到GPU\n",
    "X_test_gpu = X_test_tensor.to(device)\n",
    "\n",
    "# 最终评估（使用测试集）\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred_score = model(X_test_gpu)\n",
    "    \n",
    "    # 移动到CPU进行后续处理\n",
    "    test_pred_score_np = test_pred_score.cpu().numpy().flatten()\n",
    "    y_test_np = y_test_tensor.numpy()\n",
    "\n",
    "# 计算最终指标\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test_np, test_pred_score_np))\n",
    "final_mae = np.mean(np.abs(y_test_np - test_pred_score_np))\n",
    "final_r2 = r2_score(y_test_np, test_pred_score_np)\n",
    "\n",
    "print(\"\\nFinal Test Results:\")\n",
    "print(f\"RMSE: {final_rmse:.6f}\")\n",
    "print(f\"MAE: {final_mae:.6f}\")\n",
    "print(f\"R² Score: {final_r2:.6f}\")\n",
    "\n",
    "# 检查risk_score的最终输出范围\n",
    "print(f\"\\nRisk Score Output Range: [{test_pred_score_np.min():.6f}, {test_pred_score_np.max():.6f}]\")\n",
    "print(f\"True Risk Score Range: [{y_test_np.min():.6f}, {y_test_np.max():.6f}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3c272",
   "metadata": {},
   "source": [
    "### 输出结果图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba4e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 损失曲线\n",
    "plt.subplot(2, 3, 1)\n",
    "train_losses = np.log10(np.array(train_losses))\n",
    "plt.plot(train_losses, label='Train Loss', color='blue', alpha=0.7)\n",
    "# plt.plot(val_losses, label='Validation Loss', color='red', alpha=0.7)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('log10(LossMS)')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "\n",
    "# 预测 vs 真实风险评分\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.scatter(y_test_np, test_pred_score_np, alpha=0.6)\n",
    "plt.plot([0, 1], [0, 1], 'r--', alpha=0.8, label='Perfect Prediction')\n",
    "plt.xlabel('True Risk Score')\n",
    "plt.ylabel('Predicted Risk Score')\n",
    "plt.title('Risk Score Prediction Performance')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 残差图\n",
    "plt.subplot(2, 3, 5)\n",
    "residuals = test_pred_score_np - y_test_np\n",
    "plt.scatter(test_pred_score_np, residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='red', linestyle='--', alpha=0.8)\n",
    "plt.xlabel('Predicted Risk Score')\n",
    "plt.ylabel('Residuals (Predicted - True)')\n",
    "plt.title('Prediction Residuals')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 预测值分布\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.hist(test_pred_score_np, bins=50, alpha=0.7, color='blue', label='Predicted')\n",
    "plt.hist(y_test_np, bins=50, alpha=0.7, color='red', label='True')\n",
    "plt.xlabel('Risk Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Predicted vs True Scores')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30afc1c3",
   "metadata": {},
   "source": [
    "### 输出验证集结果的统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c1c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出详细统计信息\n",
    "print(\"\\nDetailed Prediction Statistics:\")\n",
    "print(f\"Predicted Risk Score - Min: {test_pred_score_np.min():.6f}\")\n",
    "print(f\"Predicted Risk Score - Max: {test_pred_score_np.max():.6f}\")\n",
    "print(f\"Predicted Risk Score - Mean: {test_pred_score_np.mean():.6f}\")\n",
    "print(f\"Predicted Risk Score - Std: {test_pred_score_np.std():.6f}\")\n",
    "\n",
    "print(f\"\\nTrue Risk Score - Min: {y_test_np.min():.6f}\")\n",
    "print(f\"True Risk Score - Max: {y_test_np.max():.6f}\")\n",
    "print(f\"True Risk Score - Mean: {y_test_np.mean():.6f}\")\n",
    "print(f\"True Risk Score - Std: {y_test_np.std():.6f}\")\n",
    "\n",
    "# 分位数分析\n",
    "print(f\"\\nQuantile Analysis:\")\n",
    "quantiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "pred_quantiles = np.quantile(test_pred_score_np, quantiles)\n",
    "true_quantiles = np.quantile(y_test_np, quantiles)\n",
    "\n",
    "for q, pred_q, true_q in zip(quantiles, pred_quantiles, true_quantiles):\n",
    "    print(f\"  {q:.0%} Quantile - Predicted: {pred_q:.4f}, True: {true_q:.4f}, Diff: {pred_q-true_q:.4f}\")\n",
    "\n",
    "# 性能评估\n",
    "print(f\"\\nPerformance Evaluation:\")\n",
    "if final_rmse < 0.05:\n",
    "    print(f\"  RMSE: {final_rmse:.4f} - Excellent prediction accuracy\")\n",
    "elif final_rmse < 0.1:\n",
    "    print(f\"  RMSE: {final_rmse:.4f} - Good prediction accuracy\")\n",
    "elif final_rmse < 0.15:\n",
    "    print(f\"  RMSE: {final_rmse:.4f} - Fair prediction accuracy\")\n",
    "else:\n",
    "    print(f\"  RMSE: {final_rmse:.4f} - Poor prediction accuracy\")\n",
    "\n",
    "if final_r2 > 0.8:\n",
    "    print(f\"  R²: {final_r2:.4f} - Excellent model fit\")\n",
    "elif final_r2 > 0.6:\n",
    "    print(f\"  R²: {final_r2:.4f} - Good model fit\")\n",
    "elif final_r2 > 0.4:\n",
    "    print(f\"  R²: {final_r2:.4f} - Fair model fit\")\n",
    "else:\n",
    "    print(f\"  R²: {final_r2:.4f} - Poor model fit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da_venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
